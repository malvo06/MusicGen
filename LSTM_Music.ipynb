{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message, merge_tracks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation, Dropout, Flatten, Bidirectional\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directly open a midi file\n",
    "mid = MidiFile('Debussy.mid')\n",
    "\n",
    "\n",
    "for msg in mid:\n",
    "    if not msg.is_meta and msg.channel == 0 and msg.type == 'note_on':\n",
    "        data = msg.bytes()\n",
    "        notes.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the path\n",
    "path='data/ff7/'\n",
    "\n",
    "\n",
    "notes = []\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".mid\"):\n",
    "        #print(filename)\n",
    "        mid = MidiFile(path + '/' + filename)\n",
    "        for msg in mid:\n",
    "            if not msg.is_meta and msg.channel = msg.type == 'note_on':\n",
    "                data = msg.bytes()\n",
    "                notes.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the notes\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.array(notes).reshape(-1,1))\n",
    "notes = list(scaler.transform(np.array(notes).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = [list(note) for note in notes]\n",
    "\n",
    "# subsample data for training and prediction\n",
    "X = []\n",
    "y = []\n",
    "# number of notes in a batch\n",
    "n_prev = 30\n",
    "for i in range(0, len(notes)-n_prev):\n",
    "    X.append(notes[i:i+n_prev])\n",
    "    y.append(notes[i+n_prev])\n",
    "\n",
    "X=np.array(X)\n",
    "y=np.array(y)    \n",
    "\n",
    "# save a portion of the music for prediction\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X,y,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(256, input_shape=(n_prev, 1), return_sequences=True)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128, input_shape=(n_prev, 1), return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(64, input_shape=(n_prev, 1), return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "filepath=\"./checkpoint/checkpoint_model_ff7{epoch:02d}.hdf5\"\n",
    "model_save_callback = ModelCheckpoint(filepath, monitor='val_acc', \n",
    "                                      verbose=1, save_best_only=False, \n",
    "                                      mode='auto', save_freq=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "499/974 [==============>...............] - ETA: 1:07 - loss: 0.3507\n",
      "Epoch 00001: saving model to ./checkpoint/checkpoint_model_ff701.hdf5\n",
      "974/974 [==============================] - 132s 136ms/step - loss: 0.3498\n",
      "Epoch 2/5\n",
      " 25/974 [..............................] - ETA: 2:08 - loss: 0.3644\n",
      "Epoch 00002: saving model to ./checkpoint/checkpoint_model_ff702.hdf5\n",
      "525/974 [===============>..............] - ETA: 1:07 - loss: 0.3493\n",
      "Epoch 00002: saving model to ./checkpoint/checkpoint_model_ff702.hdf5\n",
      "974/974 [==============================] - 141s 145ms/step - loss: 0.3498\n",
      "Epoch 3/5\n",
      " 51/974 [>.............................] - ETA: 1:51 - loss: 0.3450\n",
      "Epoch 00003: saving model to ./checkpoint/checkpoint_model_ff703.hdf5\n",
      "551/974 [===============>..............] - ETA: 58s - loss: 0.3490\n",
      "Epoch 00003: saving model to ./checkpoint/checkpoint_model_ff703.hdf5\n",
      "974/974 [==============================] - 129s 133ms/step - loss: 0.3498\n",
      "Epoch 4/5\n",
      " 77/974 [=>............................] - ETA: 2:44 - loss: 0.3478\n",
      "Epoch 00004: saving model to ./checkpoint/checkpoint_model_ff704.hdf5\n",
      "577/974 [================>.............] - ETA: 52s - loss: 0.3481\n",
      "Epoch 00004: saving model to ./checkpoint/checkpoint_model_ff704.hdf5\n",
      "974/974 [==============================] - 129s 132ms/step - loss: 0.3498\n",
      "Epoch 5/5\n",
      "103/974 [==>...........................] - ETA: 1:49 - loss: 0.3535\n",
      "Epoch 00005: saving model to ./checkpoint/checkpoint_model_ff705.hdf5\n",
      "603/974 [=================>............] - ETA: 45s - loss: 0.3486\n",
      "Epoch 00005: saving model to ./checkpoint/checkpoint_model_ff705.hdf5\n",
      "974/974 [==============================] - 130s 133ms/step - loss: 0.3498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21544c04e0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True,\n",
    "                 epochs=5,\n",
    "                 callbacks=[model_save_callback],\n",
    "                 verbose=1)\n",
    "#fit(X, y, 20, 1, verbose=1, callbacks=[model_save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(np.array(X_test))\n",
    "prediction = np.squeeze(prediction)\n",
    "prediction = np.squeeze(scaler.inverse_transform(prediction.reshape(-1,1)))\n",
    "prediction = [int(i) for i in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = MidiTrack()\n",
    "t = 0\n",
    "for note in prediction:\n",
    "    # 147 means note_on\n",
    "    # 67 is velosity\n",
    "    note = np.asarray([147, note, 110])\n",
    "    bytes = note.astype(int)\n",
    "    msg = Message.from_bytes(bytes[0:3])\n",
    "    t += 1\n",
    "    msg.time = t\n",
    "    track.append(msg)\n",
    "mid.tracks.append(track)\n",
    "mid.save('results/ff7_ep5.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('green_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
