{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message, merge_tracks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation, Dropout, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from keras import utils, Input\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beethoven_hammerklavier_2.mid\n",
      "beethoven_les_adieux_2.mid\n",
      "beethoven_opus10_2.mid\n",
      "beethoven_opus22_2.mid\n",
      "beethoven_opus22_3.mid\n"
     ]
    }
   ],
   "source": [
    "#specify the path\n",
    "path='music/classical-piano-type0/beethoven'\n",
    "\n",
    "\n",
    "notes = []\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".mid\"):\n",
    "        print(filename)\n",
    "        mid = MidiFile(path + '/' + filename)\n",
    "        for msg in mid:\n",
    "            if not msg.is_meta and msg.channel == 0 and  msg.type == 'note_on':\n",
    "                data = msg.bytes()\n",
    "                notes.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  91  92  93  94  95  96  98 100 101]\n"
     ]
    }
   ],
   "source": [
    "notes_set = np.unique(list(notes))\n",
    "total_notes = len(notes_set)\n",
    "print(notes_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 35\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    network_output = utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = prepare_sequences(notes,total_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(512, input_shape=(X.shape[1:]), return_sequences=True)))\n",
    "model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, input_shape=(X.shape[1:]),  return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(total_notes,activation='softmax')) \n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "filepath=\"./checkpoint/checkpoint_model_ff7{epoch:02d}.hdf5\"\n",
    "model_save_callback = ModelCheckpoint(filepath, monitor='loss', \n",
    "                                      verbose=1, save_best_only=False, \n",
    "                                      mode='min', save_freq=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "175/265 [==================>...........] - ETA: 1:36 - loss: 3.4529\n",
      "Epoch 00001: saving model to ./checkpoint\\checkpoint_model_ff701.hdf5\n",
      "265/265 [==============================] - 284s 1s/step - loss: 3.4473\n",
      "Epoch 2/10\n",
      "265/265 [==============================] - 288s 1s/step - loss: 3.4141\n",
      "Epoch 3/10\n",
      "145/265 [===============>..............] - ETA: 2:07 - loss: 3.3758\n",
      "Epoch 00003: saving model to ./checkpoint\\checkpoint_model_ff703.hdf5\n",
      "176/265 [==================>...........] - ETA: 1:35 - loss: 3.3803"
     ]
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "                 batch_size=64,\n",
    "                 shuffle=True,\n",
    "                 epochs=10,\n",
    "                 callbacks=[model_save_callback],\n",
    "                 verbose=1)\n",
    "#fit(X, y, 20, 1, verbose=1, callbacks=[model_save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.randint(0, len(X)-1)\n",
    "prediction  = []\n",
    "\n",
    "for i in range(10):\n",
    "    pred = np.reshape(X[rand], (1, len(X[rand]), 1))\n",
    "    #normalize\n",
    "    pred = pred / float(total_notes)\n",
    "    pred_res = model.predict(pred)\n",
    "    index = np.argmax(pred_res)\n",
    "    prediction.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(X)-1)\n",
    "\n",
    "random_music = X[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(500):\n",
    "\n",
    "    random_music = random_music.reshape(1,len(random_music),1)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = MidiTrack()\n",
    "t = 0\n",
    "\n",
    "for note in predictions:\n",
    "    # 147 means note_on\n",
    "    # 67 is velosity\n",
    "    note = np.asarray([147, note, 110])\n",
    "    bytes = note.astype(int)\n",
    "    msg = Message.from_bytes(bytes[0:3])\n",
    "    t += 1\n",
    "    msg.time = t\n",
    "    track.append(msg)\n",
    "\n",
    "newFile = MidiFile()\n",
    "newFile.tracks.append(track)\n",
    "newFile.save('beethoven_epoch5_softmax.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('green_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
