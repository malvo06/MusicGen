{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "import os\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the path\n",
    "path='music/classical-piano-type0/mix'\n",
    "\n",
    "\n",
    "notes = []\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".mid\"):\n",
    "        #print(filename)\n",
    "        mid = MidiFile(path + '/' + filename)\n",
    "        for msg in mid:\n",
    "            if not msg.is_meta and msg.channel == 0 and msg.type == 'note_on':\n",
    "                data = msg.bytes()\n",
    "                notes.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.array(notes).reshape(-1,1))\n",
    "notes = list(scaler.transform(np.array(notes).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layers requires that data must have a certain shape\n",
    "# create list of lists fist\n",
    "notes = [list(note) for note in notes]\n",
    "\n",
    "# subsample data for training and prediction\n",
    "X = []\n",
    "y = []\n",
    "# number of notes in a batch\n",
    "n_prev = 80\n",
    "for i in range(len(notes)-n_prev):\n",
    "    X.append(notes[i:i+n_prev])\n",
    "    y.append(notes[i+n_prev])\n",
    "    \n",
    "# save a seed to do prediction later\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(n_prev, 1), return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128, input_shape=(n_prev, 1), return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(64, input_shape=(n_prev, 1), return_sequences=False))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "filepath=\"./checkpoint/checkpoint_model_{epoch:02d}.hdf5\"\n",
    "model_save_callback = ModelCheckpoint(filepath, monitor='val_acc', \n",
    "                                      verbose=1, save_best_only=False, \n",
    "                                      mode='auto', save_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50/466 [==>...........................] - ETA: 1:50 - loss: 0.0653\n",
      "Epoch 00001: saving model to ./checkpoint\\checkpoint_model_01.hdf5\n",
      "100/466 [=====>........................] - ETA: 1:43 - loss: 0.0495\n",
      "Epoch 00001: saving model to ./checkpoint\\checkpoint_model_01.hdf5\n",
      "150/466 [========>.....................] - ETA: 1:29 - loss: 0.0427\n",
      "Epoch 00001: saving model to ./checkpoint\\checkpoint_model_01.hdf5\n",
      "200/466 [===========>..................] - ETA: 1:13 - loss: 0.0388\n",
      "Epoch 00001: saving model to ./checkpoint\\checkpoint_model_01.hdf5\n",
      "250/466 [===============>..............] - ETA: 59s - loss: 0.0361\n",
      "Epoch 00001: saving model to ./checkpoint\\checkpoint_model_01.hdf5\n",
      "300/466 [==================>...........] - ETA: 45s - loss: 0.0342\n",
      "Epoch 00001: saving model to ./checkpoint\\checkpoint_model_01.hdf5\n",
      "350/466 [=====================>........] - ETA: 32s - loss: 0.0327\n",
      "Epoch 00001: saving model to ./checkpoint\\checkpoint_model_01.hdf5\n",
      "400/466 [========================>.....] - ETA: 18s - loss: 0.0315\n",
      "Epoch 00001: saving model to ./checkpoint\\checkpoint_model_01.hdf5\n",
      "450/466 [===========================>..] - ETA: 4s - loss: 0.0305\n",
      "Epoch 00001: saving model to ./checkpoint\\checkpoint_model_01.hdf5\n",
      "466/466 [==============================] - 135s 278ms/step - loss: 0.0302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1718c129d60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X), np.array(y), 50, 1, verbose=1, callbacks=[model_save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(np.array(X_test))\n",
    "prediction = np.squeeze(prediction)\n",
    "prediction = np.squeeze(scaler.inverse_transform(prediction.reshape(-1,1)))\n",
    "prediction = [int(i) for i in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = MidiTrack()\n",
    "t = 0\n",
    "for note in prediction:\n",
    "    # 147 means note_on\n",
    "    # 67 is velosity\n",
    "    note = np.asarray([147, note, 70])\n",
    "    bytes = note.astype(int)\n",
    "    msg = Message.from_bytes(bytes[0:3])\n",
    "    t += 1\n",
    "    msg.time = t\n",
    "    track.append(msg)\n",
    "\n",
    "newFile = MidiFile()\n",
    "newFile.tracks.append(track)\n",
    "newFile.save('mix_epoch1.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
